%!TEX root = main.tex
\section{Discussion}
Rather surprisingly no instances were found where adding an invariance regularization improved performance. It was expected that the synthetic dataset ``rays'' would be well suited for scale invariance, ``diagonal'' for offset invariance and ``circle'' and ``dist'' for rotational invariance. However, if one looks at the structure of the generated class probability function for the ``rays''-dataset one might argue, subjectively, that it does appear like the scale invariant network captures the true structure better than the network without the regularizer. In particular, without regularization the network seems to generate a higher probability of the red class the further away from origon a point is located whereas  the regularized networks probability function does fan out from origon (see figure \ref{fig:example-models}).

In the sex classification case (\cref{tab:results-speaker}) it's seen that for both TIMIT and ELSDSR the network models perform better than the GMM on MFCC. This is not surprising for the Dieleman models, as they should be able to learn features similar or better than the MFCC features. However the logistic regression model also performs better, this is perhaps expected as sex classification don't require a lot of information, thus mean frequencies may suffice. Finally the logistic regression learns using all observations simultaneously, while GMM learns from just one sex at a time which could result in a worse performance.

In the speaker classification case (\cref{tab:results-speaker}) the GMM also performs worse than logistic regression, though in the ELSDSR case it is not significant. This is more surprising as speaker classification should be much harder and thus require more information, but this does not appear to be the case. Finally the Dieleman model performs significantly worse than logistic regression, this is perhaps the most surprising result as it should at the very least be able to learn something similarly to logistic regression. This could suggest that there may be a vanishing moment problem, however the network is able to overfit and the output distribution of the individual layers don't support this.

Finally we can report that adding Weight Decay do improve the Dieleman model slightly, however it is not by much. In the original Dieleman paper \cite{dieleman} it was found that adding Weight Decay did not improve the performance, and we do suspect it may also be the case for our problem. In our weight decay optimization there are 27 choices ($\lambda \in [10^{-10}, 5 \cdot 10^{-2}]$), that we think could have the same performance as $\lambda = 0$. Thus with a $95\%$ confidence interval we can expect $1.35$ of those tests to be a type 1 error (false rejection). We suspect that $\lambda = 5 \cdot 10^{-3}$ may be a false rejection.

\subsection{Analysis on generated datasets}
It could be speculated that the proposed invariance regularizer is ill suited for classification problems. In these problems it is primarily the area in the vicinity of the decision boundary which is critical. Since the method only evaluates the invariance in the observation points, most evaluations might have little bearing on the decision boundary. In addition, for classification one has to choose which of the class outputs are chosen for the penalty term ($C_{i,k}$). In this paper, for each observation we chose the output-neuron matching the target class for the observation. One could argue that if the network is erroneously giving the target class a low probability then the derivate might also be low. Experiments were made using the output-neuron with maximum activation but it did not seem to make a difference.

Finally it should be noted that depending on the network the computation of the invariance is quite slow. In particular the combination of convolution and max-pool layers increased computation time so much that even the relatively small dataset of timit took 30-45 minutes to train on a nVidia Titan-X. So in many cases it might be more simple and efficient to introduces invariance by adding extra artifical data to the training set.
